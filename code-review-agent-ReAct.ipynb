{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66ca035",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict\n",
    "import openai\n",
    "import os\n",
    "\n",
    "\n",
    "## Set up the tools and tools registry\n",
    "\n",
    "def read_file(filepath: str) -> str:\n",
    "    \"\"\"Read contents of a Python file\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        return f\"File not found: {filepath}\"\n",
    "    \n",
    "    with open(filepath, \"r\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def analyze_code(code: str) -> str:\n",
    "    \"\"\"Ask an LLM to analyze the provided code.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful code review assistant.\n",
    "    Analyze the following Python code and suggest one improvement.\n",
    "\n",
    "    Code:\n",
    "    {code}\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.responses.create(model=\"gpt-4.1-mini\",input=[{\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "    return response.output_text\n",
    "\n",
    "def patch_file(filepath: str, content: str) -> str:\n",
    "    \"\"\"Writes the given content to a file, completely replacing its current content.\"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"w\") as f:\n",
    "            f.write(content)\n",
    "        return f\"File successfully updated: {filepath}. New content written.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error writing to file {filepath}: {e}\"\n",
    "        \n",
    "class ToolRegistry:\n",
    "    \"\"\"Holds available tools and dispatches them by name.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.tools: Dict[str,Callable] = {}\n",
    "    \n",
    "    def register(self, name:str, func: Callable):\n",
    "        self.tools[name] = func\n",
    "\n",
    "    def call(self, name:str, *args, **kwargs):\n",
    "        if name not in self.tools:\n",
    "            return f\"Unknown tool: {name}\"\n",
    "        return self.tools[name](*args, **kwargs)\n",
    "\n",
    "import tiktoken\n",
    "import json\n",
    "\n",
    "class CodeReviewAgentReAct:\n",
    "    def __init__(self,tools_registry: ToolRegistry, model=\"gpt-4.1\",memory_file=\"agent_memory.json\",summarize_after=10,max_context_tokens=6000):\n",
    "        self.tools = tools_registry\n",
    "        self.model = model\n",
    "        self.conversation_history = [] # Short-term memory\n",
    "        self.memory_file = memory_file\n",
    "        self.load_long_term_memory() # Long-term memory (key-value store)\n",
    "        self.conversation_summary = \"\" # Summarized conversation history\n",
    "        self.summarize_after = summarize_after\n",
    "        self.turns_since_summary = 0\n",
    "        self.max_context_tokens = max_context_tokens\n",
    "        \n",
    "\n",
    "        # Initialize tokenizer for the model\n",
    "        try:\n",
    "            self.tokenizer = tiktoken.encoding_for_model(model)\n",
    "        except:\n",
    "            self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    def count_tokens(self, text:str) -> int:\n",
    "        \"\"\"Count tokens in a string\"\"\"\n",
    "        return len(self.tokenizer.encode(text))\n",
    "    \n",
    "    def trim_history_to_fit(self, system_message:str):\n",
    "        \"\"\"Remove old messages until we fit within the token budget\"\"\"\n",
    "\n",
    "        # Count tokens in system message\n",
    "        fixed_tokens = self.count_tokens(system_message)\n",
    "\n",
    "        # Count tokens in conversation history\n",
    "        history_tokens = sum([self.count_tokens(msg[\"content\"]) for msg in self.conversation_history])\n",
    "\n",
    "        total_tokens = fixed_tokens + history_tokens\n",
    "\n",
    "        while total_tokens > self.max_context_tokens and len(self.conversation_history) > 2:\n",
    "            removed_msg = self.conversation_history.pop(0)\n",
    "            total_tokens -= self.count_tokens(removed_msg[\"content\"])\n",
    "\n",
    "        return total_tokens\n",
    "\n",
    "\n",
    "    def summarize_history(self):\n",
    "        \"\"\"Use LLM to summarize the conversation so far.\"\"\"\n",
    "        if len(self.conversation_history) < 3:\n",
    "            return\n",
    "        \n",
    "        history_text = \"\\n\".join([f\"{msg[\"role\"]}:{msg[\"content\"]}\" for msg in self.conversation_history])\n",
    "\n",
    "        summary_prompt = f\"\"\"Summarize this conversation in 3-4 sentences,\n",
    "        preserving key fact, decisions, and actions taken:\n",
    "        {history_text}\n",
    "\n",
    "        Previous Summary: {self.conversation_summary or 'None'}\n",
    "        \"\"\"\n",
    "\n",
    "        response = openai.responses.create(model=self.model, input=[{\"role\":\"user\",\"content\":summary_prompt}])\n",
    "\n",
    "        self.conversation_summary = response.output_text\n",
    "\n",
    "        # Keep only the last few turns + the summary\n",
    "        recent_turns = self.conversation_history[-4:] # Keep the last 4 messages (2 user/assistant exchanges)\n",
    "\n",
    "        self.conversation_history = recent_turns\n",
    "        self.turns_since_summary = 0\n",
    "\n",
    "\n",
    "    def remember(self, key:str, value: str):\n",
    "        \"\"\"Retrieve information from long term memory.\"\"\"\n",
    "        self.long_term_memory[key] = value\n",
    "        self.save_long_term_memory()\n",
    "    \n",
    "    def recall(self,key:str) -> str:\n",
    "        \"\"\"Retrieve information from long term memory\"\"\"\n",
    "        return self.long_term_memory.get(key,\"No memory found for this key.\")\n",
    "    \n",
    "    def get_relevant_memories(self) -> str:\n",
    "        \"\"\"Format long term memories for inclusion in prompts.\"\"\"\n",
    "        if not self.long_term_memory:\n",
    "            return \"No stored memories\"\n",
    "        \n",
    "        memories = \"\\n\".join([f\"- {k}:{v}\" for k, v in self.long_term_memory.items()])\n",
    "        return f\"Relevant memories:\\n{memories}\"\n",
    "    \n",
    "    def save_long_term_memory(self):\n",
    "        \"\"\"Persist long term memory to JSON file\"\"\"\n",
    "        try:\n",
    "            with open(self.memory_file,\"w\") as f:\n",
    "                json.dump(self.long_term_memory,f,indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not save memory to {self.memory_file}:  {e}\")\n",
    "\n",
    "    def load_long_term_memory(self):\n",
    "        \"\"\"Load long term memory from JSON file\"\"\"\n",
    "        if os.path.exists(self.memory_file):\n",
    "            try:\n",
    "                with open(self.memory_file, 'r') as f:\n",
    "                    self.long_term_memory = json.load(f)\n",
    "                print(f\"Loaded {len(self.long_term_memory)} memories from {self.memory_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not load memory from {self.memory_file}: {e}\")\n",
    "        else:\n",
    "            self.long_term_memory = {}\n",
    "\n",
    "    def think(self, user_input:str):\n",
    "        \"\"\"LLM decides which tool to use with both short term and long term context.\"\"\"\n",
    "        # Add user message to history\n",
    "        self.conversation_history.append({\"role\":\"user\",\"content\":user_input})\n",
    "\n",
    "        self.turns_since_summary += 1\n",
    "\n",
    "        # Check if we should summarize\n",
    "        if self.turns_since_summary >= self.summarize_after:\n",
    "            self.summarize_history()\n",
    "\n",
    "        #Include long term memory & summary in system context\n",
    "        system_message_context = f\"\"\"You are a code assistant with access to these tools:\n",
    "                - read_file(filepath)\n",
    "                - analyze_code(code)\n",
    "                - patch_file(filepath,content)\n",
    "\n",
    "                {self.get_relevant_memories()}\n",
    "\n",
    "                Conversation Summary: {self.conversation_summary or 'This is the start of the conversation'}\n",
    "\n",
    "                Decide which tool to use based on the conversation, conversation summary and relevant memories.\n",
    "\n",
    "                Follow the ReAct pattern: **Thought**, then **Action** or a final **Answer**\n",
    "                **Format your response STRICTLY as follows:**\n",
    "\n",
    "                1. Thought:Your internal reasoning and plan.\n",
    "                2. Action:The tool call to make in JSON format {{\"tool\": \"tool_name\", \"args\": [\"arg1\", \"arg2\"]}} (e.g., {{\"tool\":\"patch_file\", \"args\":[\"file_path\",\"content\"]}}. **OR**\n",
    "                3. Answer:Your final human-readable response.\n",
    "\n",
    "                After each action you will receive an observation which is a result from the tool call\n",
    "                DO NOT include any previous thoughts or observations from the conversation history\n",
    "                DO NOT include any observation\n",
    "\n",
    "                Reply only with \n",
    "                Thought:reasoning or plan\n",
    "                Action:tool_call\n",
    "             \n",
    "                Only provide an Answer: if you have completed the task based on a tool call result\n",
    "                If based on a tool call result you have completed the task respond with ONLY\n",
    "                Thought:reasoning\n",
    "                Answer:why based on the latest observation the task is complete\n",
    "\n",
    "                Example exchange\n",
    "                initial user query\n",
    "                User: Review and fix the code in auth.py\n",
    "\n",
    "                your response\n",
    "                Thought: I need to use the tool read_file(auth.py) to review its code\n",
    "                Action:{{\"tool\":\"read_file\",\"args\":[\"auth.py\"]}}\n",
    "\n",
    "                response from tool call\n",
    "                Observation: return user_store.username = user_name\n",
    "\n",
    "                your response\n",
    "                Thought:I have found the issue. the code is using an assignment instead of comparison so the code will not work. I will use the tool patch_file to correct the code.\n",
    "                Action: {{\"tool\":\"patch_file\",\"args\":[\"auth.py\",\"return user_store.username == user_name\"]}}\n",
    "\n",
    "                response from tool call\n",
    "                Observation: successfully applied patch to file auth.py\n",
    "\n",
    "                your response\n",
    "                Thought: The code in auth.py has been updated. I will now read the updated auth.py to confirm\n",
    "                Action:{{\"tool\":\"read_file\",\"args\":[\"auth.py\"]}}\n",
    "\n",
    "                response from tool call\n",
    "                Observation: \"return user_store.username == user_name\"\n",
    "\n",
    "                your response\n",
    "                Thought: The auth.py file now has the updated code. This task is complete\n",
    "                Answer: Task is complete because the auth.py file now has the correct code\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "        self.trim_history_to_fit(system_message_context)\n",
    "        \n",
    "        # Build prompt with system instructions\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\":\"system\",\n",
    "                \"content\":system_message_context\n",
    "            }\n",
    "        ] + self.conversation_history\n",
    "\n",
    "        response = openai.responses.create(model=self.model, input=messages)\n",
    "\n",
    "        decision = response.output_text\n",
    "\n",
    "        # Add assistant's decision to conversation history\n",
    "        self.conversation_history.append({\n",
    "            \"role\":\"assistant\",\n",
    "            \"content\": decision\n",
    "        })\n",
    "\n",
    "        return decision\n",
    "    \n",
    "    def act(self, decision:str):\n",
    "        \"\"\"Execute the chosen tool and record the result.\"\"\"\n",
    "        try:\n",
    "            parsed = json.loads(decision)\n",
    "            tool_name = parsed[\"tool\"]\n",
    "            args = parsed.get(\"args\",[])\n",
    "\n",
    "            result = self.tools.call(tool_name,*args)\n",
    "            self.conversation_history.append({\"role\":\"system\",\"content\":result})\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error executing tool: {e}\"\n",
    "            self.conversation_history.append({\n",
    "                \"role\":\"system\",\n",
    "                \"content\": error_msg\n",
    "            })\n",
    "            \n",
    "            return error_msg\n",
    "\n",
    "    def run(self, user_query:str, max_iterations=3):\n",
    "        \"\"\"\n",
    "        Main execution loop with reflection.\n",
    "        Args:\n",
    "            user_query: The user's request\n",
    "            max_iterations: Maxumum number of think-act-reflect cycles. this is to avoid the agent getting stuck in a loop.\n",
    "        \n",
    "        Returns:\n",
    "            Final response string\n",
    "        \"\"\"\n",
    "        step = 0\n",
    "\n",
    "        current_input = user_query\n",
    "\n",
    "        while step < max_iterations:\n",
    "            print(f\"\\n--- Step {step+1} ---\")\n",
    "\n",
    "            llm_response = self.think(current_input)\n",
    "\n",
    "            print(f\"Agent's LLM Response:\\n{llm_response}\")\n",
    "\n",
    "            if \"Answer:\" in llm_response:\n",
    "                final_answer = llm_response.split(\"Answer:\",1)[1].strip()\n",
    "                print(f\"\\n Agent Finished: \\n {final_answer}\")\n",
    "                return final_answer\n",
    "            if \"Action:\" in llm_response:\n",
    "                action_line = llm_response.split(\"Action:\",1)[1].split(\"\\n\")[0].strip()\n",
    "                print(f\"Acting: {action_line}\")\n",
    "\n",
    "                tool_result = self.act(action_line)\n",
    "\n",
    "                print(f\"\\nTool Result:\\n{tool_result}\")\n",
    "                current_input = f\"Observation:{tool_result}\"\n",
    "            else:\n",
    "                error_msg = f\"LLM did not provide valid Action or Answer: LLM Respose:: {llm_response}\"\n",
    "                print(f\"\\n Error: {error_msg}\")\n",
    "                return error_msg\n",
    "            \n",
    "            step +=1\n",
    "        \n",
    "        return \"Max steps reached without a final answer\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
