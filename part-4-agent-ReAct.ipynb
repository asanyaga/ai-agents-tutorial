{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1925c27",
   "metadata": {},
   "source": [
    "# Agents That Think: Introducing the ReAct Pattern\n",
    "In our previous tutorials, we established the basic building blocks of an LLM agent. We implemented the **observe**,**think**,**act** loop, we added **tool use** and **memory**.  \n",
    "Our agent can now read code, suggest improvements and remember past interactions.\n",
    "\n",
    "However, what happens when the agent makes a mistake, or its suggested action doesn't achieve the desired outcome? This is where **reflection** comes in. In this tutorial, we'll introduce the **ReAct pattern** and show how to enable our agent to evaluate its own actions, identify errors, and self correct making it a more reliable and autonomous assistant.\n",
    "\n",
    "## The ReAct Pattern: Think, Act, Observe\n",
    "The **ReAct**(Reasoning and Acting) pattern is a powerful paradigm that combines **Reasoning** steps with **Action** steps performed via tools.\n",
    "* **Thought(Reasoning)**: The LLM internally reasons about the current situation and determines the next **Action** to take.\n",
    "* **Action**: The agent executes the chosen action (e.g. calling a tool like `read_file(sample.py)`)\n",
    "* **Observation** The result of the action (tool output) is returned to the agent, serving as the observation for the next turn.\n",
    "\n",
    "Our current agent already follows the Observe, Think, Act sequence. The **reflection pattern** a layer to the **thought** step, allowing the agent to evaluate its past steps and observations before proceeding\n",
    "\n",
    "### Why Reflection is Essential for Agent Success\n",
    "* **Self-correction**: Reflection allows the agent to recognize when a tool call failed or when the output didn't align with the goal.\n",
    "* **Plan Adjustment**: The agent can assess the progress of the plan and modify its approach dynamically. For instance if `analyze_code` suggests a fix, the reflection step can verify that the suggested fix actually addresses the original problem.\n",
    "* **Increased Robustness**: By incorporating a dedicated step to evaluate its outputs, the agent becomes less prone to \"hallucination\" and its responses are more grounded in real world tool outputs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4ad447",
   "metadata": {},
   "source": [
    "### Implementing the ReaAct agent\n",
    "We are going to add a new tool for the agent to be able to apply any fixes to code that it suggests\n",
    "\n",
    "```python\n",
    "import os\n",
    "import json\n",
    "\n",
    "def patch_file(file_path:str, content: str) -> str:\n",
    "    \"\"\"Writes the given content to a file, completely replacing its current content\"\"\"\n",
    "    try:\n",
    "        with open(file_path,\"w\") as f:\n",
    "            f.write(content)\n",
    "        return f\"File succesfully updated: {file_path}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error writing to file {file_path}: {e}\"\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "### The Agent code so far\n",
    "We will make changes to this agent code to demonstrate a simple implementation of the ReAct pattern\n",
    "\n",
    "```python\n",
    "import tiktoken # OpenAI token counting library\n",
    "\n",
    "class CodeReviewAgent:\n",
    "    def __init__(self,tools_registry: ToolRegistry, model=\"gpt-4o-mini\",memory_file=\"agent_memory.json\",summarize_after=10,max_context_tokens=6000):\n",
    "        self.tools = tools_registry\n",
    "        self.model = model\n",
    "        self.conversation_history = [] # Short-term memory\n",
    "        self.memory_file = memory_file\n",
    "        self.load_long_term_memory() # Long-term memory (key-value store)\n",
    "        self.conversation_summary = \"\" # Summarized conversation history\n",
    "        self.summarize_after = summarize_after\n",
    "        self.turns_since_summary = 0\n",
    "        self.max_context_tokens = max_context_tokens\n",
    "\n",
    "        # Initialize tokenizer for the model\n",
    "        try:\n",
    "            self.tokenizer = tiktoken.encoding_for_model(model)\n",
    "        except:\n",
    "            self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    def count_tokens(self, text:str) -> int:\n",
    "        \"\"\"Count tokens in a string\"\"\"\n",
    "        return len(self.tokenizer.encode(text))\n",
    "    \n",
    "    def trim_history_to_fit(self, system_message:str):\n",
    "        \"\"\"Remove old messages until we fit within the token budget\"\"\"\n",
    "\n",
    "        # Count tokens in system message\n",
    "        fixed_tokens = self.count_tokens(system_message)\n",
    "\n",
    "        # Count tokens in conversation history\n",
    "        history_tokens = sum([self.count_tokens(msg[\"content\"]) for msg in self.conversation_history])\n",
    "\n",
    "        total_tokens = fixed_tokens + history_tokens\n",
    "\n",
    "        while total_tokens > self.max_context_tokens and len(self.conversation_history) > 2:\n",
    "            removed_msg = self.conversation_history.pop(0)\n",
    "            total_tokens -= self.count_tokens(removed_msg[\"content\"])\n",
    "\n",
    "        return total_tokens\n",
    "\n",
    "\n",
    "    def summarize_history(self):\n",
    "        \"\"\"Use LLM to summarize the conversation so far.\"\"\"\n",
    "        if len(self.conversation_history) < 3:\n",
    "            return\n",
    "        \n",
    "        history_text = \"\\n\".join([f\"{msg[\"role\"]}:{msg[\"content\"]}\" for msg in self.conversation_history])\n",
    "\n",
    "        summary_prompt = f\"\"\"Summarize this conversation in 3-4 sentences,\n",
    "        preserving key fact, decisions, and actions taken:\n",
    "        {history_text}\n",
    "\n",
    "        Previous Summary: {self.conversation_summary or 'None'}\n",
    "        \"\"\"\n",
    "\n",
    "        response = openai.responses.create(model=self.model, input=[{\"role\":\"user\",\"content\":summary_prompt}])\n",
    "\n",
    "        self.conversation_summary = response.output_text\n",
    "\n",
    "        # Keep only the last few turns + the summary\n",
    "        recent_turns = self.conversation_history[-4:] # Keep the last 4 messages (2 user/assistant exchanges)\n",
    "\n",
    "        self.conversation_history = recent_turns\n",
    "        self.turns_since_summary = 0\n",
    "\n",
    "\n",
    "    def remember(self, key:str, value: str):\n",
    "        \"\"\"Retrieve information from long term memory.\"\"\"\n",
    "        self.long_term_memory[key] = value\n",
    "        self.save_long_term_memory()\n",
    "    \n",
    "    def recall(self,key:str) -> str:\n",
    "        \"\"\"Retrieve information from long term memory\"\"\"\n",
    "        return self.long_term_memory.get(key,\"No memory found for this key.\")\n",
    "    \n",
    "    def get_relevant_memories(self) -> str:\n",
    "        \"\"\"Format long term memories for inclusion in prompts.\"\"\"\n",
    "        if not self.long_term_memory:\n",
    "            return \"No stored memories\"\n",
    "        \n",
    "        memories = \"\\n\".join([f\"- {k}:{v}\" for k, v in self.long_term_memory.items()])\n",
    "        return f\"Relevant memories:\\n{memories}\"\n",
    "    \n",
    "    def save_long_term_memory(self):\n",
    "        \"\"\"Persist long term memory to JSON file\"\"\"\n",
    "        try:\n",
    "            with open(self.memory_file,\"w\") as f:\n",
    "                json.dump(self.long_term_memory,f,indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not save memory to {self.memory_file}:  {e}\")\n",
    "\n",
    "    def load_long_term_memory(self):\n",
    "        \"\"\"Load long term memory from JSON file\"\"\"\n",
    "        if os.path.exists(self.memory_file):\n",
    "            try:\n",
    "                with open(self.memory_file, 'r') as f:\n",
    "                    self.long_term_memory = json.load(f)\n",
    "                print(f\"Loaded {len(self.long_term_memory)} memories from {self.memory_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not load memory from {self.memory_file}: {e}\")\n",
    "        else:\n",
    "            self.long_term_memory = {}\n",
    "\n",
    "    def think(self, user_input:str):\n",
    "        \"\"\"LLM decides which tool to use with both short term and long term context.\"\"\"\n",
    "        # Add user message to history\n",
    "        self.conversation_history.append({\"role\":\"user\",\"content\":user_input})\n",
    "\n",
    "        self.turns_since_summary += 1\n",
    "\n",
    "        # Check if we should summarize\n",
    "        if self.turns_since_summary >= self.summarize_after:\n",
    "            self.summarize_history()\n",
    "\n",
    "        #Include long term memory & summary in system context\n",
    "        system_message_context = f\"\"\"You are a code assistant with access to these tools:\n",
    "                - read_file(filepath)\n",
    "                - analyze_code(code)\n",
    "\n",
    "                {self.get_relevant_memories()}\n",
    "\n",
    "                Conversation Summary: {self.conversation_summary or 'This is the start of the conversation'}\n",
    "\n",
    "                Decide which tool to use based on the conversation, conversation summary and relevant memories.\n",
    "                Reply ONLY with the tool name and argument.\n",
    "                Examples: read_file(\"main.py\") or analyze_code(\"def foo():pass\")\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "        self.trim_history_to_fit(system_message_context)\n",
    "        \n",
    "        # Build prompt with system instructions\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\":\"system\",\n",
    "                \"content\":system_message_context\n",
    "            }\n",
    "        ] + self.conversation_history\n",
    "\n",
    "        response = openai.responses.create(model=self.model, input=messages)\n",
    "\n",
    "        decision = response.output_text\n",
    "\n",
    "        # Add assistant's decision to conversation history\n",
    "        self.conversation_history.append({\n",
    "            \"role\":\"assistant\",\n",
    "            \"content\": decision\n",
    "        })\n",
    "\n",
    "        return decision\n",
    "    \n",
    "    def act(self, decision:str):\n",
    "        \"\"\"Execute the chosen tool and record the result.\"\"\"\n",
    "        try:\n",
    "            if \"(\" in decision and \")\" in decision:\n",
    "                name, arg = decision.split(\"(\",1)\n",
    "                arg = arg.strip(\")'\\\"\")\n",
    "                result = self.tools.call(name.strip(),arg)\n",
    "            else:\n",
    "                result = self.tools.call(decision)\n",
    "\n",
    "            #Store tool call result in conversation history\n",
    "            self.conversation_history.append({\n",
    "                \"role\":\"system\",\n",
    "                \"content\":f\"Tool result: {result}\"\n",
    "            })\n",
    "\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error executing tool: {e}\"\n",
    "            self.conversation_history.append({\n",
    "                \"role\":\"system\",\n",
    "                \"content\": error_msg\n",
    "            })\n",
    "            return error_msg\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da894407",
   "metadata": {},
   "source": [
    "### Set up the tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bdfc852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Dict\n",
    "import openai\n",
    "import os\n",
    "\n",
    "\n",
    "## Set up the tools and tools registry\n",
    "\n",
    "def read_file(filepath: str) -> str:\n",
    "    \"\"\"Read contents of a Python file\"\"\"\n",
    "    if not os.path.exists(filepath):\n",
    "        return f\"File not found: {filepath}\"\n",
    "    \n",
    "    with open(filepath, \"r\") as f:\n",
    "        return f.read()\n",
    "\n",
    "def analyze_code(code: str) -> str:\n",
    "    \"\"\"Ask an LLM to analyze the provided code.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are a helpful code review assistant.\n",
    "    Analyze the following Python code and suggest one improvement.\n",
    "\n",
    "    Code:\n",
    "    {code}\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.responses.create(model=\"gpt-4.1-mini\",input=[{\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "    return response.output_text\n",
    "\n",
    "def patch_file(filepath: str, content: str) -> str:\n",
    "    \"\"\"Writes the given content to a file, completely replacing its current content.\"\"\"\n",
    "    try:\n",
    "        with open(filepath, \"w\") as f:\n",
    "            f.write(content)\n",
    "        return f\"File successfully updated: {filepath}. New content written.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error writing to file {filepath}: {e}\"\n",
    "        \n",
    "class ToolRegistry:\n",
    "    \"\"\"Holds available tools and dispatches them by name.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.tools: Dict[str,Callable] = {}\n",
    "    \n",
    "    def register(self, name:str, func: Callable):\n",
    "        self.tools[name] = func\n",
    "\n",
    "    def call(self, name:str, *args, **kwargs):\n",
    "        if name not in self.tools:\n",
    "            return f\"Unknown tool: {name}\"\n",
    "        return self.tools[name](*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20965e5",
   "metadata": {},
   "source": [
    "### Implement the ReAct Agent\n",
    "* Add a `run()` method to manage the think, reflect, act loop\n",
    "```python\n",
    "    def run(self, user_query:str, max_iterations=3):\n",
    "        \"\"\"\n",
    "        Main execution loop with reflection.\n",
    "        Args:\n",
    "            user_query: The user's request\n",
    "            max_iterations: Maxumum number of think-act-reflect cycles. this is to avoid the agent getting stuck in a loop.\n",
    "        \n",
    "        Returns:\n",
    "            Final response string\n",
    "        \"\"\"\n",
    "        step = 0\n",
    "\n",
    "        current_input = user_query\n",
    "\n",
    "        while step < max_iterations:\n",
    "            print(f\"\\n--- Step {step+1} ---\")\n",
    "\n",
    "            llm_response = self.think(current_input)\n",
    "\n",
    "            print(f\"Agent's LLM Response:\\n{llm_response}\")\n",
    "\n",
    "            if \"Answer:\" in llm_response:\n",
    "                final_answer = llm_response.split(\"Answer:\",1)[1].strip()\n",
    "                print(f\"\\n Agent Finished: \\n {final_answer}\")\n",
    "                return final_answer\n",
    "            if \"Action:\" in llm_response:\n",
    "                action_line = llm_response.split(\"Action:\",1)[1].split(\"\\n\")[0].strip()\n",
    "                print(f\"Acting: {action_line}\")\n",
    "\n",
    "                tool_result = self.act(action_line)\n",
    "\n",
    "                print(f\"\\nTool Result:\\n{tool_result}\")\n",
    "                current_input = f\"Observation:{tool_result}\"\n",
    "            else:\n",
    "                error_msg = f\"LLM did not provide valid Action or Answer: LLM Respose:: {llm_response}\"\n",
    "                print(f\"\\n Error: {error_msg}\")\n",
    "                return error_msg\n",
    "            \n",
    "            step +=1\n",
    "        \n",
    "        return \"Max steps reached without a final answer\"\n",
    "```\n",
    "* Update the `system_message_context` prompt in `think()` to implement the ReAct pattern\n",
    "* The ReAct pattern is implemented by a prompt engineering technique where we give the LLM a crafted promnpt that directs it to reflect on past actions and respond with the next action.  \n",
    "Note that we give the LLM a specific output format. Note that the output format for the **Action** is specified to be JSON so that we can have better tool calling control.\n",
    "\n",
    "\n",
    "**NOTE:** As noted earlier in the tools tutorial, most modern LLM have specific tool calling and structured output conventions that would give more predictable structured output.  \n",
    "In this example, we keep things simple by telling the LLM how to format its response so it can work with most LLMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38ce3d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "import json\n",
    "\n",
    "class CodeReviewAgentReAct:\n",
    "    def __init__(self,tools_registry: ToolRegistry, model=\"gpt-4.1\",memory_file=\"agent_memory.json\",summarize_after=10,max_context_tokens=6000):\n",
    "        self.tools = tools_registry\n",
    "        self.model = model\n",
    "        self.conversation_history = [] # Short-term memory\n",
    "        self.memory_file = memory_file\n",
    "        self.load_long_term_memory() # Long-term memory (key-value store)\n",
    "        self.conversation_summary = \"\" # Summarized conversation history\n",
    "        self.summarize_after = summarize_after\n",
    "        self.turns_since_summary = 0\n",
    "        self.max_context_tokens = max_context_tokens\n",
    "        \n",
    "\n",
    "        # Initialize tokenizer for the model\n",
    "        try:\n",
    "            self.tokenizer = tiktoken.encoding_for_model(model)\n",
    "        except:\n",
    "            self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "    def count_tokens(self, text:str) -> int:\n",
    "        \"\"\"Count tokens in a string\"\"\"\n",
    "        return len(self.tokenizer.encode(text))\n",
    "    \n",
    "    def trim_history_to_fit(self, system_message:str):\n",
    "        \"\"\"Remove old messages until we fit within the token budget\"\"\"\n",
    "\n",
    "        # Count tokens in system message\n",
    "        fixed_tokens = self.count_tokens(system_message)\n",
    "\n",
    "        # Count tokens in conversation history\n",
    "        history_tokens = sum([self.count_tokens(msg[\"content\"]) for msg in self.conversation_history])\n",
    "\n",
    "        total_tokens = fixed_tokens + history_tokens\n",
    "\n",
    "        while total_tokens > self.max_context_tokens and len(self.conversation_history) > 2:\n",
    "            removed_msg = self.conversation_history.pop(0)\n",
    "            total_tokens -= self.count_tokens(removed_msg[\"content\"])\n",
    "\n",
    "        return total_tokens\n",
    "\n",
    "\n",
    "    def summarize_history(self):\n",
    "        \"\"\"Use LLM to summarize the conversation so far.\"\"\"\n",
    "        if len(self.conversation_history) < 3:\n",
    "            return\n",
    "        \n",
    "        history_text = \"\\n\".join([f\"{msg[\"role\"]}:{msg[\"content\"]}\" for msg in self.conversation_history])\n",
    "\n",
    "        summary_prompt = f\"\"\"Summarize this conversation in 3-4 sentences,\n",
    "        preserving key fact, decisions, and actions taken:\n",
    "        {history_text}\n",
    "\n",
    "        Previous Summary: {self.conversation_summary or 'None'}\n",
    "        \"\"\"\n",
    "\n",
    "        response = openai.responses.create(model=self.model, input=[{\"role\":\"user\",\"content\":summary_prompt}])\n",
    "\n",
    "        self.conversation_summary = response.output_text\n",
    "\n",
    "        # Keep only the last few turns + the summary\n",
    "        recent_turns = self.conversation_history[-4:] # Keep the last 4 messages (2 user/assistant exchanges)\n",
    "\n",
    "        self.conversation_history = recent_turns\n",
    "        self.turns_since_summary = 0\n",
    "\n",
    "\n",
    "    def remember(self, key:str, value: str):\n",
    "        \"\"\"Retrieve information from long term memory.\"\"\"\n",
    "        self.long_term_memory[key] = value\n",
    "        self.save_long_term_memory()\n",
    "    \n",
    "    def recall(self,key:str) -> str:\n",
    "        \"\"\"Retrieve information from long term memory\"\"\"\n",
    "        return self.long_term_memory.get(key,\"No memory found for this key.\")\n",
    "    \n",
    "    def get_relevant_memories(self) -> str:\n",
    "        \"\"\"Format long term memories for inclusion in prompts.\"\"\"\n",
    "        if not self.long_term_memory:\n",
    "            return \"No stored memories\"\n",
    "        \n",
    "        memories = \"\\n\".join([f\"- {k}:{v}\" for k, v in self.long_term_memory.items()])\n",
    "        return f\"Relevant memories:\\n{memories}\"\n",
    "    \n",
    "    def save_long_term_memory(self):\n",
    "        \"\"\"Persist long term memory to JSON file\"\"\"\n",
    "        try:\n",
    "            with open(self.memory_file,\"w\") as f:\n",
    "                json.dump(self.long_term_memory,f,indent=2)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not save memory to {self.memory_file}:  {e}\")\n",
    "\n",
    "    def load_long_term_memory(self):\n",
    "        \"\"\"Load long term memory from JSON file\"\"\"\n",
    "        if os.path.exists(self.memory_file):\n",
    "            try:\n",
    "                with open(self.memory_file, 'r') as f:\n",
    "                    self.long_term_memory = json.load(f)\n",
    "                print(f\"Loaded {len(self.long_term_memory)} memories from {self.memory_file}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not load memory from {self.memory_file}: {e}\")\n",
    "        else:\n",
    "            self.long_term_memory = {}\n",
    "\n",
    "    def think(self, user_input:str):\n",
    "        \"\"\"LLM decides which tool to use with both short term and long term context.\"\"\"\n",
    "        # Add user message to history\n",
    "        self.conversation_history.append({\"role\":\"user\",\"content\":user_input})\n",
    "\n",
    "        self.turns_since_summary += 1\n",
    "\n",
    "        # Check if we should summarize\n",
    "        if self.turns_since_summary >= self.summarize_after:\n",
    "            self.summarize_history()\n",
    "\n",
    "        #Include long term memory & summary in system context\n",
    "        system_message_context = f\"\"\"You are a code assistant with access to these tools:\n",
    "                - read_file(filepath)\n",
    "                - analyze_code(code)\n",
    "                - patch_file(filepath,content)\n",
    "\n",
    "                {self.get_relevant_memories()}\n",
    "\n",
    "                Conversation Summary: {self.conversation_summary or 'This is the start of the conversation'}\n",
    "\n",
    "                Decide which tool to use based on the conversation, conversation summary and relevant memories.\n",
    "\n",
    "                Follow the ReAct pattern: **Thought**, then **Action** or a final **Answer**\n",
    "                **Format your response STRICTLY as follows:**\n",
    "\n",
    "                1. Thought:Your internal reasoning and plan.\n",
    "                2. Action:The tool call to make in JSON format {{\"tool\": \"tool_name\", \"args\": [\"arg1\", \"arg2\"]}} (e.g., {{\"tool\":\"patch_file\", \"args\":[\"file_path\",\"content\"]}}. **OR**\n",
    "                3. Answer:Your final human-readable response.\n",
    "\n",
    "                After each action you will receive an observation which is a result from the tool call\n",
    "                DO NOT include any previous thoughts or observations from the conversation history\n",
    "                DO NOT include any observation\n",
    "\n",
    "                Reply only with \n",
    "                Thought:reasoning or plan\n",
    "                Action:tool_call\n",
    "             \n",
    "                Only provide an Answer: if you have completed the task based on a tool call result\n",
    "                If based on a tool call result you have completed the task respond with ONLY\n",
    "                Thought:reasoning\n",
    "                Answer:why based on the latest observation the task is complete\n",
    "\n",
    "                Example exchange\n",
    "                initial user query\n",
    "                User: Review and fix the code in auth.py\n",
    "\n",
    "                your response\n",
    "                Thought: I need to use the tool read_file(auth.py) to review its code\n",
    "                Action:{{\"tool\":\"read_file\",\"args\":[\"auth.py\"]}}\n",
    "\n",
    "                response from tool call\n",
    "                Observation: return user_store.username = user_name\n",
    "\n",
    "                your response\n",
    "                Thought:I have found the issue. the code is using an assignment instead of comparison so the code will not work. I will use the tool patch_file to correct the code.\n",
    "                Action: {{\"tool\":\"patch_file\",\"args\":[\"auth.py\",\"return user_store.username == user_name\"]}}\n",
    "\n",
    "                response from tool call\n",
    "                Observation: successfully applied patch to file auth.py\n",
    "\n",
    "                your response\n",
    "                Thought: The code in auth.py has been updated. I will now read the updated auth.py to confirm\n",
    "                Action:{{\"tool\":\"read_file\",\"args\":[\"auth.py\"]}}\n",
    "\n",
    "                response from tool call\n",
    "                Observation: \"return user_store.username == user_name\"\n",
    "\n",
    "                your response\n",
    "                Thought: The auth.py file now has the updated code. This task is complete\n",
    "                Answer: Task is complete because the auth.py file now has the correct code\n",
    "\n",
    "                \"\"\"\n",
    "\n",
    "        self.trim_history_to_fit(system_message_context)\n",
    "        \n",
    "        # Build prompt with system instructions\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\":\"system\",\n",
    "                \"content\":system_message_context\n",
    "            }\n",
    "        ] + self.conversation_history\n",
    "\n",
    "        response = openai.responses.create(model=self.model, input=messages)\n",
    "\n",
    "        decision = response.output_text\n",
    "\n",
    "        # Add assistant's decision to conversation history\n",
    "        self.conversation_history.append({\n",
    "            \"role\":\"assistant\",\n",
    "            \"content\": decision\n",
    "        })\n",
    "\n",
    "        return decision\n",
    "    \n",
    "    def act(self, decision:str):\n",
    "        \"\"\"Execute the chosen tool and record the result.\"\"\"\n",
    "        try:\n",
    "            parsed = json.loads(decision)\n",
    "            tool_name = parsed[\"tool\"]\n",
    "            args = parsed.get(\"args\",[])\n",
    "\n",
    "            result = self.tools.call(tool_name,*args)\n",
    "            self.conversation_history.append({\"role\":\"system\",\"content\":result})\n",
    "            return result\n",
    "        except Exception as e:\n",
    "            error_msg = f\"Error executing tool: {e}\"\n",
    "            self.conversation_history.append({\n",
    "                \"role\":\"system\",\n",
    "                \"content\": error_msg\n",
    "            })\n",
    "            \n",
    "            return error_msg\n",
    "\n",
    "    def run(self, user_query:str, max_iterations=3):\n",
    "        \"\"\"\n",
    "        Main execution loop with reflection.\n",
    "        Args:\n",
    "            user_query: The user's request\n",
    "            max_iterations: Maxumum number of think-act-reflect cycles. this is to avoid the agent getting stuck in a loop.\n",
    "        \n",
    "        Returns:\n",
    "            Final response string\n",
    "        \"\"\"\n",
    "        step = 0\n",
    "\n",
    "        current_input = user_query\n",
    "\n",
    "        while step < max_iterations:\n",
    "            print(f\"\\n--- Step {step+1} ---\")\n",
    "\n",
    "            llm_response = self.think(current_input)\n",
    "\n",
    "            print(f\"Agent's LLM Response:\\n{llm_response}\")\n",
    "\n",
    "            if \"Answer:\" in llm_response:\n",
    "                final_answer = llm_response.split(\"Answer:\",1)[1].strip()\n",
    "                print(f\"\\n Agent Finished: \\n {final_answer}\")\n",
    "                return final_answer\n",
    "            if \"Action:\" in llm_response:\n",
    "                action_line = llm_response.split(\"Action:\",1)[1].split(\"\\n\")[0].strip()\n",
    "                print(f\"Acting: {action_line}\")\n",
    "\n",
    "                tool_result = self.act(action_line)\n",
    "\n",
    "                print(f\"\\nTool Result:\\n{tool_result}\")\n",
    "                current_input = f\"Observation:{tool_result}\"\n",
    "            else:\n",
    "                error_msg = f\"LLM did not provide valid Action or Answer: LLM Respose:: {llm_response}\"\n",
    "                print(f\"\\n Error: {error_msg}\")\n",
    "                return error_msg\n",
    "            \n",
    "            step +=1\n",
    "        \n",
    "        return \"Max steps reached without a final answer\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496642cb",
   "metadata": {},
   "source": [
    "### Run the agent\n",
    "Let's run the agent and give it a more complex task to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5182123b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_registry = ToolRegistry()\n",
    "\n",
    "# Register the tools we defined above\n",
    "tool_registry.register(\"read_file\", read_file)\n",
    "tool_registry.register(\"analyze_code\",analyze_code)\n",
    "tool_registry.register(\"patch_file\",patch_file)\n",
    "\n",
    "agent = CodeReviewAgentReAct(tools_registry=tool_registry)\n",
    "\n",
    "agent.run(user_query=\"Review the code in sample.py and fix any issues you find\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2cc752a",
   "metadata": {},
   "source": [
    "## What's next\n",
    "In this tutorial we have implemented a simple ReAct agent that 'thinks' about what actions to take based on the input that it's been given.\n",
    "\n",
    "In the next part of the series we will look at more advanced patterns such as routing, planning, orchestration and multi agent workflows. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
